---
title: "Geographical analysis of media"
subtitle: "4. Hypercubes creation"
author: "Claude Grasland"
output: html_notebook
---


```{r setup2, echo = FALSE, comment = FALSE, warning = FALSE, message = FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = FALSE, warning = FALSE)
library(knitr)
library(dplyr)
library(quanteda)
library(data.table)
library(tidytext)
```




# Hypercubes


This section is based on the TELEMAC application elaborated during the H2020 projected ODYCCEUS and presented in the paper published in the journal *Frontiers* and available at https://analytics.huma-num.fr/Claude.Grasland/telemac/ 

Our objective is to elaborate an hypercube organised by different dimensions. As an example, we suppose that we are interested in the analysis of the crisis of migrant and refugees (what) in different newspapers (who), at different period of time (when) and we want to explore the locations of countries that are mentioned (where) and eventually associated together (where1.where2). Finally we want to distinguish inside the news the possible changes of results if we consider the title or the first, second and third sentences of the description (order). 



## Definition of dimensions


To illustrate this different options, we can look at the example of a news published by the Algerian newspaper El Watan the 16th September 2015 and divided in a title and three sentences of description.


```{r examp1}
qd<-readRDS("data/corpus/qd_mycorpus_states_topics.RDS")

examp<-corpus_subset(qd,docid(qd) == 9486265)

kable(paste(examp))

```


Thanks to the previous operations of geographical and topical tagging, we can propose a simplified table where the text of the news has been removed and where we keep only the information of interest for the agregation procedure.

```{r examp2}
examp$id<-as.character(docid(examp))
dtexamp<-data.table(tidy(examp)) %>% select(id=id, order = order, who = who, when=day, what=mobil, where1 = states, where2=states)
kable(dtexamp)

```

The hypercube is the result of an aggregation of foreign news according several dimensions:

-   **who** : this dimension is related to the variable which describe the media outlets which published the RSS feeds.
Each source is related to a code`ll_sss_xxxxxx` where `ll`is the language, `sss`is the ISO3 code of the country and `xxxxxx`the name of the media. 
For instance, a RSS feed produced by the Algerian newspaper *El Watan* is identified by the code who = `fr_DZA_elwata`. 
Starting from there, it is then possible to proceed to aggregation of the data by group of languages (eg. computation of the indicators for all the French speaking newspapers) or countries (compute the indicators for all the media outlets located in Algeria).

-   **when** : this dimension describe the day when an article of the RSS feeds has been published, according to a reference time zone (Paris in present case).
Starting from the day, the data will be further aggregated according to different period of aggregation: weeks, months, quarters or years. . 
For instance, by choosing to work on monthly aggregated data, the first period of observation for the news presented as example  will be: `when = 2015-09-01`. If we choose a division in weeks, we have to decide if the week start on Sunday (default option of R) or start on Monday (option adopted in present case)

-   **where1** and **where2** : this dual dimension is associated to the cross-list of foreign countries detected by the country dictionary in the news. 
For example the second sentence of our exampple ("*L’Allemagne, l’Autriche et la Slovaquie ont appelé, hier, à la tenue, dès la semaine prochaine, d’un conseil européen des chefs d’Etat et de gouvernement consacré à la crise migratoire.*") has produced a list of three places (*DEU,AUT,SVK*) associated to the cross-list of nine couple of places (*AUT-AUT, AUT-DEU, AUT-SVK, DEU-DEU, DEU-AUT, DEU-SVK, SVK-AUT, SVK-DEU, SVK-SVK*) where each couple will receive a weight of 1/9. It is important to keep in mind that the countries where the media are located (mentioned in the `who` dimension) should be excluded from the list if we decide to work only on foreign news. 

-   **what** : In general, this dimension can be described as a boolean value (*TRUE/FALSE*) which precise if the news is associated or not to the topic of interest. For example the title and the two first sentences of our example are associated to the topic of international mobility but not the third sentence where the expected keywords has not been found. But if we have introduced subtopics, the situation is more complex because the news can be associated to different subtopics (as it was associated to different states).  For example the second sentence of the description (*"Après l’échec lundi de la réunion extraordinaire à Bruxelles des ministres de l’Intérieur de l’Union européenne (UE) sur la répartition des réfugiés par quotas, l’Allemagne, l’Autriche et la Slovaquie ont appelé hier à la tenue, dès la semaine prochaine, d’un conseil européen des chefs d’Etat et de gouvernement consacré à la crise migratoire, rapporte l’AFP"*) is associated to 2 subtopics (refug, migr) and 4 countries (BEL, AUT, DEU, SVK). It will therefore be broken in 2 x 4 x4 = 32 pieces of information, each of them associated to a value of 1/16th. 

- **order** : To build the hypercube, it is possible to works on different size of text units: (`order=1`): the title or the first sentence, or (`order = 2,3,4, ...`): the title with the selected number of sentence of the description available. This parameter is important because some results, especially regarding the spatial dimension of the analysis (where) are more noticeable on longer texts. In our example, it is clear that the conclusions would be different if we had decided to focus only on the title which does not mention any country and is only associated to the subtopic of refugees. 



## Aggregation function

The elaboration of the hypercube is based on the crossing of all dimensions with one line for each singular combination. To do that, we have elaborated a specific function that combine all the 6 dimensions but can be easily adapted if less dimensions are needed. 

```{r}

#' @title create an hypercube
#' @name hypercube
#' @description create a network of interlinked states
#' @param corpus a corpus of news in quanteda format
#' @param order an order of sentences in the news
#' @param who the source dimension
#' @param when the time dimension
#' @param timespan aggreation of time
#' @param what a list of topics
#' @param where1 a list of states
#' @param where2  a list of states


hypercube   <- function( corpus = qd,
                        order = "order",
                        who = "source",
                        when = "when",
                        timespan = "week",
                        what = "what",
                        where1 = "where1",
                        where2 = "where2")
{


  
# prepare data

  don<-docvars(corpus)
  
  df<-data.table(id     = docid(corpus),
                 order  = don[[order]],
                 who    = don[[who]],
                 when   = don[[when]],
                 what   = don[[what]],
                 where1 = don[[where1]],
                 where2 = don[[where2]])

  # adjust id
 df$id<-paste(df$id,"_",df$order,sep="")
 
# change time span
  df$when<-as.character(cut(as.Date(df$when), timespan, start.on.monday = TRUE))

# unnest where1
  df$where1[df$where1==""]<-"_no_"
  df<-unnest_tokens(df,where1,where1,to_lower=F)
  
# unnest where2
  df$where2[df$where2==""]<-"_no_"
  df<-unnest_tokens(df,where2,where2,to_lower=F) 
  
# unnest what
  df$what[df$what==""]<-"_no_"
  df<-unnest_tokens(df,what,what,to_lower=F) 
  


# Compute weight of news
  newswgt<-df[,list(wgt=1/.N),list(id)]
  df <- merge(df,newswgt, by="id")


# ------------------------ Hypercube creation --------------------#
  
  
# Aggregate
  hc<- df[,.(tags = .N, news=sum(wgt)) ,.(order,who, when,where1,where2, what)]
  
# Convert date to time
  hc$when<-as.Date(hc$when)
  
# export
  return(hc)
  
}

```


In order to test the function, we apply it firstly on our small example of the single news published by El Watan

```{r}
hc_test<-hypercube( corpus   = examp,
                    order    = "order",
                    who      = "who",
                    when     = "when",
                    timespan = "day",
                    what     = "mobil",
                    where1   = "states",
                    where2   = "states")
kable(hc_test)
```









- *order = 1* : the title is described by a single line because we have only one subtopic and no states mentioned. The weight of the line is 1. 
- *order = 2* : the first sentence of description is characterized by one subtopic and three different states which produce 9 lines with weight of 1/9 = 0.111 news.
- *order = 3* : the second sentence of description is characterized by two subtopic and four diffeent states which produce 32 lines with weight of 1/32 = 0.031 news.
- *order = 4* : the last sentence of description is characterized by no topics  and 2 states which produce 4 lines with weight of O.25.


## Application

Of course it is not interesting to transform a single news in such a large table. But it is of high interest if we realize the agregation on a large number of news. Because in this case the number of combination of dimensions is limited and we can obtain a synthetic table called hypercube that summarize all the information extracted from the news in a relatively small object. The time of computation of an hypercube can be relatively large and the memory size necessary to the intermediary step of disagregation can be important, but the resulting object is small and very adapted for a large number of exploration and modelisation methods.

In practice, the function based on data.table package appears to be very fast as we can see in the following example 


```{r}
hc<-hypercube( corpus   = qd,
                    order    = "order",
                    who      = "who",
                    when     = "when",
                    timespan = "day",
                    what     = "mobil",
                    where1   = "states",
                    where2   = "states")

saveRDS(hc,"data/corpus/hc_mycorpus_states_mobil_day.RDS")
paste("Size of resulting file = ",round(file.size("data/corpus/hc_mycorpus_states_mobil_day.RDS")/1000000,3), "Mo")
```






